---
layout: prose.njk
title: 3.2
---

# Virtual memory management

- We have discussed various memory management strategies.

- Main purpose is to keep many processes in memory simultaneously to allow multiprogramming.

- However, they tend to require that an entire process be in memory before it can execute. Hence the process that can be loaded on to the main memory is often limited by the size of the main memory.

- We can use methods such as dynamic loading, but it requires special precautions and extra work by the programmer.

## What is virtual memory?

- It a storage scheme where secondary memory is treated as though it is a part of main memory and large processes can be stored in it. Only the part of the process that is actually needed for execution will be loaded on to the actual main memory.

![](/images/2022-02-12-15-03-04-image.png)

## Benefits of using virtual memory

- A program would no longer be constrained by the amount of physical memory that is available. Users would be able to write programs for an extremely large virtual address space, simplifying the programming task.

- Because each user program could take less physical memory, more programs could be run at the same time, with a corresponding increase in CPU utilization and throughput but with no increase in response time or turnaround time.

- Less IO would be needed to load or swap user program into memory, so each user program would run faster.

## Demand paging

### What is demand paging?

- Load pages only as they are needed.

- Pages are only loaded when they are demanded during program execution.

- Pages that are never accessed are thus never loaded into physical memory.

### Demand paging system

- A demand paging system is similar to a paging system with swapping where processes reside in secondary memory.

- When we want to execute a process, we swap it into memory.

### Pager

- Rather than swapping the entire process into memory, we use a lazy swapper that will never swap a page into memory unless it is needed.

- Swapper term is already used to refer to process swapper, so here we call it pager.

- A swapper manipulates entire processes, whereas a pager is concerned with the individual pages of a process.

![](/images/2022-02-12-15-23-44-image.png)

### Hardware implementation of demand paging

- In demand paging, the pages are only loaded when they are demanded during program execution. Pages that are never accessed are thus never loaded into physical memory.

- The pager takes care of swapping pages in and out of the memory.

- To distinguish between pages that are in memory and the pages that are on the disk, we make use of the present/absent (valid/invalid) bit discussed in main memory.

- If the bit is set to valid, then the page is legal and in memory. If the bit it set to invalid, the page is either not in the logical address space of the process or is valid but is currently on the disk.

![](/images/2022-02-12-15-38-03-image.png)

## Page fault

- When a process tries to access a page that is not present in memory (or marked as invalid)

- Access to invalid page causes a page-fault trap.

- The paging hardware, in translating the address through the page table, will notice that the invalid bit is set, causing a trap to the OS.

### Procedure for handling page faults

1. Check an internal table (usually kept with the PCB) for this process to determine whether the reference was legal memory access.

2. If reference was not legal, terminate the process.

3. If it was legal, but have not yet brought in that page, we now page it in.

4. Find a free frame.

5. Schedule a disk operation to read the desired page into the newly allocated frame.

6. When the disk read is complete, we modify the internal table kept with the process and the page table to indicate that the page is now in memory.

7. We restart the instruction that was interrupted by the trap. The process can now access the page as though it had always been in memory.

![](/images/2022-02-12-16-09-16-image.png)

### Performance of demand paging

- A computer system's performance can be significantly affected by demand paging.

- This is observed using Effect Access Time.

- Memory Access Time for most systems if usually 10 to 200 nanoseconds.

- If there are no page faults, the EAT will be equal to MAT.

- What is EAT if page fault occurs?

- Let P be the probability of page fault occurring.

- `AET = (1-P) x MAT + P x Page fault time`

## Page replacement

- Page replacement is the technique of swapping out pages from physical memory when there are no more free frames available, in order to make room for other pages which has to be loaded to the physical memory.

- If a process wants to use/access a page which is not present in physical memory, it will cause a page fault.

- So that page has to be now loaded into memory.

- But if there are no free frames available to that page, we have replace an existing page.

#### Steps to replace

1. Find the location of the page to be loaded on the disk.

2. If there is a free frame, use that frame and load the page into that frame.

3. If there is no free frames, use a page replacement algo to select a victim frame.

4. Write the victim frame to the disk and change the page and frame tables accordingly.

5. Read the desired page into the newly freed frame and change the page and frame tables.

6. Restart the user process.

![](/images/2022-02-12-22-11-22-image.png)

#### How to reduce page replacement service time?

- If no frames are free, two page transfers are required. This doubles the page-fault service time and increases the effective access time accordingly.

- We can use the modify (dirty) bit to reduce AET.

- If modify bit is set: That means that page has been modified and we to write that to the disk.

- If modify bit is not set: That means that the page has not been modified and it the same as the copy that is present on the disk. In this case, we don't have to overwrite this page, thus reducing AET.

## FIFO page replacement

- When page replacement is to be done, the oldest page in memory is chosen to be swapped out.

- We maintain a FIFO queue to hold the pages in memory and select the page at the head as victim. The desired process is added to the tail of the queue.

### Belady's anomaly

- We would expect that as no of frames increases, no of page faults will decrease.

- But for some sequences, no of pages faults increases with increase with no of frames at certain values.

## Optimal page replacement

- Has the lowest page fault rate and never suffers from Belady's anomaly.

- Replace the page which is not going to be called soon.

## Least recently used (LRU) page replacement

- It associates with each page that time of that page's last use.

- Replace the page which has not been used for the longest period of time.

## Thrashing

- Consider a process that doesn't have enough frames for its execution.

- So obviously a page fault will occur and we will have to use a page replacement algo and get the page in memory.

- If the page that was replaced was an actively used page, then it would also cause a fault.

- Then we will again replace a page to get back that page.

- This cycle goes on and the process is spending more time in paging than in execution. This high paging activity is called thrashing.

### Performance problems due to Thrashing

- The OS monitors CPU utilization.

- If the CPU utilization is too low, new processes are added so that degree of multiprogramming increasing.

- As processes are busy swapping pages in an out, they queue for the paging device and the ready queue becomes empty.

- Since processes are now waiting for the paging devices, the CPU utilization decreases.

- The CPU scheduler sees that the CPU utilization has decreased and in an attempt to increase CPU utilization it increases the degree of multiprogramming by bringing in new processes.

- These new processes try to take frames from the older processes hence increasing the number of page faults and increasing the queue for the paging devices.

- The CPU utilization drops even further and the cycle continues. Thrashing is occurring and the system throughput decreases tremendously.
